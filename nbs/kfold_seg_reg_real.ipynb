{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq espiownage fastai wwf # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Regression - Real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Acknowledgement: I took [Zach Mueller's Image Segmentation tutoral notebook](https://walkwithfastai.com/Segmentation) (based on the main FastAI lesson notebook) and modified it to do regression (as per Zach's suggestions) and to work with my own data.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastai espiownage==0.0.45 mrspuff typing_extensions -q --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH_VERSION=torch1.9.0; CUDA_VERSION=cu111\n",
      "CUDA available = True, Device count = 1, Current device = 0\n",
      "Device name = GeForce RTX 3080\n",
      "hostname: bengio\n",
      "espiownage version 0.0.44\n"
     ]
    }
   ],
   "source": [
    "import espiownage\n",
    "from espiownage.core import *\n",
    "sysinfo()\n",
    "print(f\"espiownage version {espiownage.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "from fastcore.xtras import Path\n",
    "\n",
    "from fastai.callback.hook import summary\n",
    "from fastai.callback.progress import ProgressCallback\n",
    "from fastai.callback.schedule import lr_find, fit_flat_cos\n",
    "\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastai.data.transforms import get_image_files, FuncSplitter, Normalize\n",
    "\n",
    "from fastai.layers import Mish   # MishJIT gives me trouble :-( \n",
    "from fastai.losses import BaseLoss, MSELossFlat, CrossEntropyLossFlat, BCEWithLogitsLossFlat\n",
    "from fastai.optimizer import ranger\n",
    "\n",
    "from fastai.torch_core import tensor\n",
    "\n",
    "from fastai.vision.augment import aug_transforms\n",
    "from fastai.vision.core import PILImage, PILMask\n",
    "from fastai.vision.data import ImageBlock, MaskBlock, imagenet_stats\n",
    "from fastai.vision.learner import unet_learner\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import resnet34\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run parameters\n",
    "These will go in WandB automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cleaner'  # choose from: cleaner, preclean, cyclegan, fake\n",
    "project = 'segreg_kfold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shawley/datasets/espiownage-cleaner\n"
     ]
    }
   ],
   "source": [
    "from mrspuff.utils import on_colab\n",
    "\n",
    "\n",
    "on_colab = on_colab()\n",
    "if on_colab:\n",
    "    path = untar_data(f'http://hedges.belmont.edu/~shawley/espiownage-{dataset}.tgz') \n",
    "else:\n",
    "    path = Path(f'/home/shawley/datasets/espiownage-{dataset}') \n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths of input lists: 1955 1955 1955\n",
      "\n",
      "The following should match up with each other and also be SAME THING each time you restart this notebook:\n",
      "06240907_proc_01617.csv\n",
      "06240907_proc_01617.png\n",
      "06240907_proc_01617_P.png\n"
     ]
    }
   ],
   "source": [
    "# bin_size = 1 worked ok. But 0.2 and 0.5 yielded nothing; the model couldn't learn at all\n",
    "bin_size = 0.7  \n",
    "maskdir = path / ('masks_'+str(bin_size))\n",
    "# We can also generate masks dynamically using `espiownage`'s `gen_masks` script:\n",
    "#!gen_masks --quiet --step={bin_size} --maskdir={maskdir} --files={str(path/'annotations')+'/*.csv'}\n",
    "\n",
    "\n",
    "path_im = path/'images'\n",
    "path_mask = path/maskdir\n",
    " \n",
    "meta_names = sorted(glob.glob(str(path/'annotations')+'/*.csv'))\n",
    "img_names = [meta_to_img_path(x, img_bank=path_im) for x in meta_names] # img_names\n",
    "mask_names = sorted(get_image_files(path_mask))\n",
    "print(\"lengths of input lists:\",len(meta_names), len(img_names), len(mask_names))\n",
    "\n",
    "# shuffle and check that things line up\n",
    "# (precaution for DIY kfold split)\n",
    "\n",
    "def shuffle_together(*ls):\n",
    "    \"shuffle any number of lists in the same way\"\n",
    "    l =list(zip(*ls))\n",
    "    random.shuffle(l)\n",
    "    return zip(*l)\n",
    "\n",
    "random.seed(0) # so you can start again/elsewhere & keep going from the same 'shuffle'\n",
    "img_names, meta_names, mask_names = shuffle_together(img_names, meta_names, mask_names)\n",
    "\n",
    "#sanity checks:\n",
    "assert len(img_names)==len(meta_names)\n",
    "assert len(img_names)==len(mask_names)\n",
    "for i in range(len(img_names)):\n",
    "    assert os.path.basename(meta_to_mask_path(meta_names[i],mask_dir=str(path_mask)+'/')) == os.path.basename(mask_names[i]), \"mask and meta don't agree\"\n",
    "    assert os.path.basename(meta_to_img_path(meta_names[i])) == os.path.basename(img_names[i]), f'{os.path.basename(meta_to_img_path(meta_names[i]))} != {os.path.basename(img_names[i])}'\n",
    "\n",
    "print(\"\\nThe following should match up with each other and also be SAME THING each time you restart this notebook:\")\n",
    "for x in [meta_names, img_names, mask_names]:\n",
    "    print(os.path.basename(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^expected output:\n",
    "```\n",
    "06240907_proc_01617.csv\n",
    "06240907_proc_01617.png\n",
    "06240907_proc_01617_P.png\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colors =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "codes =  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15']\n",
      "yrange =  16\n",
      "half =  (192, 256)\n"
     ]
    }
   ],
   "source": [
    "get_msk = lambda o: path/maskdir/f'{o.stem}_P{o.suffix}'\n",
    "\n",
    "colors = list(range(int(11/bin_size) + 1))\n",
    "print(\"colors = \",colors)\n",
    "\n",
    "codes = [str(n) for n in range(len(colors))]; \n",
    "print(\"codes = \",codes)\n",
    "\n",
    "yrange = len(codes); \n",
    "print(\"yrange = \",yrange)\n",
    "\n",
    "sz = (384, 512)\n",
    "half = tuple(int(x/2) for x in sz); \n",
    "print(\"half = \",half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression accuracy metrics\n",
    "def sr_acc_old(inp, targ):          # scores both voids and objects\n",
    "    targ = targ.squeeze(1)\n",
    "    return 1 - (inp-targ).abs().round().clamp(max=1).mean() \n",
    "\n",
    "def sr_acc(inp, targ, bin_size=1):\n",
    "    \"segmentation regression accuracy: Are we within +/- bin_size?  tries to score only objects, not voids\"\n",
    "    targ = targ.squeeze(1)  \n",
    "    inp,targ = flatten_check(inp,targ) # https://docs.fast.ai/metrics.html#flatten_check\n",
    "    mask = targ != void_code  # non_voids\n",
    "    if len(targ[mask]) == 0:  # Empty image (all void)\n",
    "        where_correct = (inp-targ).abs() < bin_size              # gonna be ~100%!\n",
    "    else:\n",
    "        where_correct = (inp[mask]-targ[mask]).abs() < bin_size  # don't count voids in metric\n",
    "    return where_correct.float().mean()\n",
    "\n",
    "# Cell\n",
    "def sr_acc05(inp, targ): return sr_acc(inp, targ, bin_size=0.5)\n",
    "def sr_acc07(inp, targ): return sr_acc(inp, targ, bin_size=0.7)\n",
    "def sr_acc1(inp, targ):  return sr_acc(inp, targ, bin_size=1)\n",
    "def sr_acc15(inp, targ): return sr_acc(inp, targ, bin_size=1.5)\n",
    "def sr_acc2(inp, targ):  return sr_acc(inp, targ, bin_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrscotthawley\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wandb setup\n",
    "!pip install wandb -qqq\n",
    "import wandb\n",
    "from fastai.callback.wandb import *\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawley/.local/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/home/shawley/.local/lib/python3.8/site-packages/torch/_tensor.py:1023: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:760.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "k = 3  # choose 0 to 4 \n",
    "\n",
    "nk = 5\n",
    "nv = int(len(img_names)/nk) # size of val set\n",
    "bgn = k*nv                   # ind to start val set\n",
    "inds = list(range(bgn, bgn+nv)) # indices for this val set\n",
    "\n",
    "db = DataBlock(blocks=(ImageBlock, MaskBlock(codes)),\n",
    "    get_items=get_image_files,\n",
    "    splitter=IndexSplitter(inds),\n",
    "    get_y=get_msk,\n",
    "    batch_tfms=[*aug_transforms(size=half, flip_vert=True), Normalize.from_stats(*imagenet_stats)])\n",
    "dls = db.dataloaders(path/'images', fnames=img_names, bs=4)\n",
    "dls.vocab = codes\n",
    "name2id = {v:k for k,v in enumerate(codes)}\n",
    "void_code = name2id['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">k=3 cleaner</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/drscotthawley/segreg_kfold\" target=\"_blank\">https://wandb.ai/drscotthawley/segreg_kfold</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/drscotthawley/segreg_kfold/runs/5ms8f1s2\" target=\"_blank\">https://wandb.ai/drscotthawley/segreg_kfold/runs/5ms8f1s2</a><br/>\n",
       "                Run data is saved locally in <code>/home/shawley/espi-work/wandb/run-20210924_201146-5ms8f1s2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawley/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- HALF SIZE TRAINING\n",
      "Training: frozen epochs...\n",
      "WandbCallback requires use of \"SaveModelCallback\" to log best model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      16.67% [2/12 01:02<05:14]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>sr_acc_old</th>\n",
       "      <th>sr_acc05</th>\n",
       "      <th>sr_acc07</th>\n",
       "      <th>sr_acc1</th>\n",
       "      <th>sr_acc15</th>\n",
       "      <th>sr_acc2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.534555</td>\n",
       "      <td>6.061792</td>\n",
       "      <td>1.310463</td>\n",
       "      <td>0.488215</td>\n",
       "      <td>0.131544</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.276798</td>\n",
       "      <td>0.392246</td>\n",
       "      <td>0.493538</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.070246</td>\n",
       "      <td>5.238260</td>\n",
       "      <td>0.956390</td>\n",
       "      <td>0.665987</td>\n",
       "      <td>0.107606</td>\n",
       "      <td>0.152313</td>\n",
       "      <td>0.279984</td>\n",
       "      <td>0.388711</td>\n",
       "      <td>0.490437</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='183' class='' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      46.80% [183/391 00:12<00:14 5.3622]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback was not able to get prediction samples -> mask_data must be a 2D array\n"
     ]
    }
   ],
   "source": [
    "opt = ranger\n",
    "\n",
    "hrfac = 1.2  # 'headroom factor'\n",
    "y_range=(0,int(len(codes)*hrfac))  # balance between \"clamping\" to range of real data vs too much \"compression\" from sigmoid nonlineari\n",
    "\n",
    "#learn = unet_learner(dls, resnet34, yrange=len(codes), loss_func=MSELossFlat(), metrics=acc_camvid, self_attention=True, act_cls=Mish, opt_func=opt)\n",
    "metrics = [mae, sr_acc_old, sr_acc05, sr_acc07, sr_acc1, sr_acc15, sr_acc2]\n",
    "\n",
    "# run parameters\n",
    "epochs, lr = 12*4, 1e-3\n",
    "\n",
    "wandb.init(project=project, name=f'k={k} {dataset}') # <-- let wandb make up names  #name=f\"k={k},e{epochs},lr{lr}\")\n",
    "learn = unet_learner(dls, resnet34, n_out=1, y_range=y_range, loss_func=MSELossFlat(), \n",
    "                     metrics=metrics, self_attention=True, act_cls=Mish, opt_func=opt,\n",
    "                     cbs=WandbCallback())\n",
    "\n",
    "#lr = learn.lr_find().valley\n",
    "#print(\"Suggested Learning Rate =\",lr)\n",
    "\n",
    "\n",
    "print(\"----- HALF SIZE TRAINING\")\n",
    "\n",
    "print(\"Training: frozen epochs...\")\n",
    "learn.fit_flat_cos(12, slice(lr))  # these frozen epochs don't yield much improvement btw\n",
    "\n",
    "print(\"unfreezing model, lowering lr by 4\")\n",
    "learn.unfreeze()\n",
    "lrs = slice(lr/400, lr/4)\n",
    "\n",
    "print(\"Training: unfrozen epochs...\")\n",
    "\n",
    "learn.fit_flat_cos(12, lrs)\n",
    "\n",
    "halfweights = 'seg_reg_real_half'\n",
    "print(f\"Saving model: {halfweights}\")\n",
    "learn.save(halfweights)\n",
    "#  Nope we're not finished! Save wandb.finish() until after Full size training.\n",
    "\n",
    "print(\"\\n----- FULL SIZE TRAINING -----\")\n",
    "\n",
    "db = DataBlock(blocks=(ImageBlock, MaskBlock(codes)),\n",
    "    get_items=get_image_files,\n",
    "    splitter=IndexSplitter(inds),\n",
    "    get_y=get_msk,\n",
    "    batch_tfms=[*aug_transforms(size=sz, flip_vert=True), Normalize.from_stats(*imagenet_stats)])\n",
    "dls = db.dataloaders(path/'images', fnames=img_names, bs=2)  # smaller batch size because we're now full size\n",
    "dls.vocab = codes\n",
    "\n",
    "learn = unet_learner(dls, resnet34, n_out=1, y_range=y_range, loss_func=MSELossFlat(), \n",
    "                     metrics=metrics, self_attention=True, act_cls=Mish, opt_func=opt,\n",
    "                     cbs=WandbCallback())\n",
    "learn.load(halfweights)\n",
    "\n",
    "#learn.lr_find(end_lr=5e-3)\n",
    "\n",
    "lr = 3e-4\n",
    "print(\"Training: frozen epochs...\")\n",
    "learn.fit_flat_cos(10, slice(lr))\n",
    "\n",
    "print(\"unfreezing model, lowering lr by...stuff\")\n",
    "learn.unfreeze()\n",
    "lrs = slice(1e-6,lr/10); lrs\n",
    "\n",
    "print(\"Training: unfrozen epochs...\")\n",
    "learn.fit_flat_cos(10, lrs)\n",
    "\n",
    "print(\"Finishing WandB\")\n",
    "wandb.finish()\n",
    "\n",
    "fullweights = 'seg_reg_real_full'\n",
    "print(f\"Saving model: {fullweights}\")\n",
    "learn.save(fullweights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "this will generate a bunch of images of segmentation masks and a list of filenames of top losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(fullweights)\n",
    "\n",
    "preds, targs, losses = learn.get_preds(with_loss=True) # validation set only\n",
    "print(preds.shape, targs.shape)\n",
    "len(preds)\n",
    "\n",
    "def save_tmask(tmask, fname='', norm=False): # save tensor mask\n",
    "    tmask_new = tmask[0].squeeze().cpu().numpy() \n",
    "    use_min, use_max = 0, np.max(np.array(colors))    # use scale of max ring count\n",
    "    if norm: use_min, use_max = tmask_new.min(), tmask_new.max()   # auto scale for just this image\n",
    "    rescaled = (255.0 / use_max * (tmask_new - use_min)).astype(np.uint8)\n",
    "    im = Image.fromarray(rescaled)\n",
    "    if fname != '': im.save(fname)\n",
    "    return im\n",
    "\n",
    "seg_img_dir = 'seg_reg_images'\n",
    "#!rm -rf {seg_img_dir};  # leave 'em\n",
    "! mkdir {seg_img_dir}\n",
    "\n",
    "results = []\n",
    "for i in range(len(preds)):\n",
    "    #line_list = [dls.valid.items[i].stem]+[round(targs[i].cpu().numpy().item(),2), round(preds[i][0].cpu().numpy().item(),2), losses[i].cpu().numpy(), i]\n",
    "    filestem = dls.valid.items[i].stem\n",
    "    line_list = [filestem]+[losses[i].cpu().numpy(), i]\n",
    "    save_tmask(preds[i], seg_img_dir+'/'+filestem+'_pred.png')\n",
    "    results.append(line_list)\n",
    "\n",
    "# store as pandas dataframe\n",
    "res_df = pd.DataFrame(results, columns=['filename', 'loss','i'])\n",
    "\n",
    "res_df = res_df.sort_values('loss', ascending=False) # top loss order\n",
    "res_df.to_csv(f'segreg_top_losses_real_k{k}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
