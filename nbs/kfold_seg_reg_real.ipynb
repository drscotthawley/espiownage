{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq espiownage fastai wwf # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Regression - Real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Acknowledgement: I took [Zach Mueller's Image Segmentation tutoral notebook](https://walkwithfastai.com/Segmentation) (based on the main FastAI lesson notebook) and modified it to do regression (as per Zach's suggestions) and to work with my own data.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastai espiownage mrspuff typing_extensions -q --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH_VERSION=torch1.9.0; CUDA_VERSION=cu111\n",
      "CUDA available = True, Device count = 1, Current device = 0\n",
      "Device name = GeForce RTX 3080\n",
      "hostname: bengio\n",
      "espiownage version 0.0.41\n"
     ]
    }
   ],
   "source": [
    "import espiownage\n",
    "from espiownage.core import *\n",
    "sysinfo()\n",
    "print(f\"espiownage version {espiownage.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from espiownage.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find the exact imports for everything we use today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shawley/datasets/espiownage-cleaner\n"
     ]
    }
   ],
   "source": [
    "from fastcore.xtras import Path\n",
    "\n",
    "from fastai.callback.hook import summary\n",
    "from fastai.callback.progress import ProgressCallback\n",
    "from fastai.callback.schedule import lr_find, fit_flat_cos\n",
    "\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastai.data.transforms import get_image_files, FuncSplitter, Normalize\n",
    "\n",
    "from fastai.layers import Mish   # MishJIT gives me trouble :-( \n",
    "from fastai.losses import BaseLoss, MSELossFlat, CrossEntropyLossFlat, BCEWithLogitsLossFlat\n",
    "from fastai.optimizer import ranger\n",
    "\n",
    "from fastai.torch_core import tensor\n",
    "\n",
    "from fastai.vision.augment import aug_transforms\n",
    "from fastai.vision.core import PILImage, PILMask\n",
    "from fastai.vision.data import ImageBlock, MaskBlock, imagenet_stats\n",
    "from fastai.vision.learner import unet_learner\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import resnet34\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from mrspuff.utils import on_colab\n",
    "\n",
    "on_colab = on_colab()\n",
    "\n",
    "if on_colab:\n",
    "    path = untar_data('http://hedges.belmont.edu/~shawley/espiownage-cleaner.tgz') \n",
    "else:\n",
    "    path = Path('/home/shawley/datasets/espiownage-cleaner') \n",
    "\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths of input lists (should be the same?): 1955 1955 1955\n",
      "colors =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "codes =  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15']\n",
      "yrange =  16\n",
      "half =  (192, 256)\n"
     ]
    }
   ],
   "source": [
    "# bin_size = 1 worked ok. But 0.2 and 0.5 yielded nothing; the model couldn't learn at all\n",
    "bin_size = 0.7  \n",
    "maskdir = path / ('masks_'+str(bin_size))\n",
    "\n",
    "# We can also generate masks dynamically using `espiownage`'s `gen_masks` script:\n",
    "#!gen_masks --quiet --step={bin_size} --maskdir={maskdir} --files={str(path/'annotations')+'/*.csv'}\n",
    "\n",
    "path_im = path/'images'\n",
    "path_lbl = path/maskdir\n",
    " \n",
    "meta_names = sorted(glob.glob(str(path/'annotations')+'/*.csv'))\n",
    "fnames = [meta_to_img_path(x, img_bank=path_im) for x in meta_names]\n",
    "random.shuffle(fnames)\n",
    "lbl_names = get_image_files(path_lbl)\n",
    "\n",
    "#sanity check:\n",
    "print(\"lengths of input lists (should be the same?):\",len(meta_names), len(fnames), len(lbl_names))\n",
    "\n",
    "get_msk = lambda o: path/maskdir/f'{o.stem}_P{o.suffix}'\n",
    "\n",
    "colors = list(range(int(11/bin_size) + 1))\n",
    "print(\"colors = \",colors)\n",
    "\n",
    "codes = [str(n) for n in range(len(colors))]; \n",
    "print(\"codes = \",codes)\n",
    "\n",
    "yrange = len(codes); \n",
    "print(\"yrange = \",yrange)\n",
    "\n",
    "sz = (384, 512)\n",
    "half = tuple(int(x/2) for x in sz); \n",
    "print(\"half = \",half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression accuracy metrics\n",
    "def sr_acc_old(inp, targ):          # scores both voids and objects\n",
    "    targ = targ.squeeze(1)\n",
    "    return 1 - (inp-targ).abs().round().clamp(max=1).mean() \n",
    "\n",
    "def sr_acc(inp, targ, bin_size=1):\n",
    "    \"segmentation regression accuracy: Are we within +/- bin_size?  tries to score only objects, not voids\"\n",
    "    targ = targ.squeeze(1)  \n",
    "    inp,targ = flatten_check(inp,targ) # https://docs.fast.ai/metrics.html#flatten_check\n",
    "    mask = targ != void_code  # non_voids\n",
    "    if len(targ[mask]) == 0:  # Empty image (all void)\n",
    "        where_correct = (inp-targ).abs() < bin_size              # gonna be ~100%!\n",
    "    else:\n",
    "        where_correct = (inp[mask]-targ[mask]).abs() < bin_size  # don't count voids in metric\n",
    "    return where_correct.float().mean()\n",
    "\n",
    "# Cell\n",
    "def sr_acc05(inp, targ): return sr_acc(inp, targ, bin_size=0.5)\n",
    "\n",
    "# Cell\n",
    "def sr_acc1(inp, targ): return sr_acc(inp, targ, bin_size=1)\n",
    "\n",
    "# Cell\n",
    "def sr_acc15(inp, targ): return sr_acc(inp, targ, bin_size=1.5)\n",
    "\n",
    "# Cell\n",
    "def sr_acc2(inp, targ): return sr_acc(inp, targ, bin_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrscotthawley\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wandb setup\n",
    "!pip install wandb -qqq\n",
    "import wandb\n",
    "from fastai.callback.wandb import *\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawley/.local/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/home/shawley/.local/lib/python3.8/site-packages/torch/_tensor.py:1023: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:760.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# set up k-fold splitting\n",
    "kfold = True\n",
    "k = 0   # set k = 0 to 4  & re-run everything from here down\n",
    "nk = 5\n",
    "nv = int(len(fnames)/nk) # size of val set\n",
    "bgn = k*nv                   # ind to start val set\n",
    "inds = list(range(bgn, bgn+nv)) # indices for this val set\n",
    "\n",
    "db = DataBlock(blocks=(ImageBlock, MaskBlock(codes)),\n",
    "    get_items=get_image_files,\n",
    "    splitter=IndexSplitter(inds),\n",
    "    get_y=get_msk,\n",
    "    batch_tfms=[*aug_transforms(size=half, flip_vert=True), Normalize.from_stats(*imagenet_stats)])\n",
    "dls = db.dataloaders(path/'images', fnames=fnames, bs=4)\n",
    "dls.vocab = codes\n",
    "name2id = {v:k for k,v in enumerate(codes)}\n",
    "void_code = name2id['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">good-wildflower-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/drscotthawley/segreg_kfold\" target=\"_blank\">https://wandb.ai/drscotthawley/segreg_kfold</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/drscotthawley/segreg_kfold/runs/2k65c6y3\" target=\"_blank\">https://wandb.ai/drscotthawley/segreg_kfold/runs/2k65c6y3</a><br/>\n",
       "                Run data is saved locally in <code>/home/shawley/espi-work/wandb/run-20210923_164301-2k65c6y3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawley/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- HALF SIZE TRAINING\n",
      "Training: frozen epochs...\n",
      "WandbCallback requires use of \"SaveModelCallback\" to log best model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/12 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>sr_acc_old</th>\n",
       "      <th>sr_acc05</th>\n",
       "      <th>sr_acc1</th>\n",
       "      <th>sr_acc15</th>\n",
       "      <th>sr_acc2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48' class='' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.28% [48/391 00:05<00:36 14.5614]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = ranger\n",
    "\n",
    "hrfac = 1.2  # 'headroom factor'\n",
    "y_range=(0,int(len(codes)*hrfac))  # balance between \"clamping\" to range of real data vs too much \"compression\" from sigmoid nonlineari\n",
    "\n",
    "#learn = unet_learner(dls, resnet34, yrange=len(codes), loss_func=MSELossFlat(), metrics=acc_camvid, self_attention=True, act_cls=Mish, opt_func=opt)\n",
    "metrics = [mae, sr_acc_old, sr_acc05, sr_acc1, sr_acc15, sr_acc2]\n",
    "\n",
    "# run parameters\n",
    "epochs, lr = 12*4, 1e-3\n",
    "\n",
    "wandb.init(project='segreg_kfold') # <-- let wandb make up names  #name=f\"k={k},e{epochs},lr{lr}\")\n",
    "learn = unet_learner(dls, resnet34, n_out=1, y_range=y_range, loss_func=MSELossFlat(), \n",
    "                     metrics=metrics, self_attention=True, act_cls=Mish, opt_func=opt,\n",
    "                     cbs=WandbCallback())\n",
    "\n",
    "#lr = learn.lr_find().valley\n",
    "#print(\"Suggested Learning Rate =\",lr)\n",
    "\n",
    "\n",
    "print(\"----- HALF SIZE TRAINING\")\n",
    "\n",
    "print(\"Training: frozen epochs...\")\n",
    "learn.fit_flat_cos(12, slice(lr))  # these frozen epochs don't yield much improvement btw\n",
    "\n",
    "print(\"unfreezing model, lowering lr by 4\")\n",
    "learn.unfreeze()\n",
    "lrs = slice(lr/400, lr/4)\n",
    "\n",
    "print(\"Training: unfrozen epochs...\")\n",
    "\n",
    "learn.fit_flat_cos(12, lrs)\n",
    "\n",
    "halfweights = 'seg_reg_real_half'\n",
    "print(f\"Saving model: {halfweights}\")\n",
    "learn.save(halfweights)\n",
    "#  Nope we're not finished! wandb.finish()\n",
    "\n",
    "print(\"\\n----- FULL SIZE TRAINING -----\")\n",
    "\n",
    "db = DataBlock(blocks=(ImageBlock, MaskBlock(codes)),\n",
    "    get_items=get_image_files,\n",
    "    splitter=IndexSplitter(inds),\n",
    "    get_y=get_msk,\n",
    "    batch_tfms=[*aug_transforms(size=sz, flip_vert=True), Normalize.from_stats(*imagenet_stats)])\n",
    "dls = db.dataloaders(path/'images', fnames=fnames, bs=2)  # smaller batch size because we're now full size\n",
    "dls.vocab = codes\n",
    "\n",
    "learn = unet_learner(dls, resnet34, n_out=1, y_range=y_range, loss_func=MSELossFlat(), \n",
    "                     metrics=metrics, self_attention=True, act_cls=Mish, opt_func=opt,\n",
    "                     cbs=WandbCallback())\n",
    "learn.load(halfweights)\n",
    "\n",
    "#learn.lr_find(end_lr=5e-3)\n",
    "\n",
    "lr = 3e-4\n",
    "print(\"Training: frozen epochs...\")\n",
    "learn.fit_flat_cos(10, slice(lr))\n",
    "\n",
    "print(\"unfreezing model, lowering lr by...stuff\")\n",
    "learn.unfreeze()\n",
    "lrs = slice(1e-6,lr/10); lrs\n",
    "\n",
    "print(\"Training: unfrozen epochs...\")\n",
    "learn.fit_flat_cos(10, lrs)\n",
    "\n",
    "print(\"Finishing WandB\")\n",
    "wandb.finish()\n",
    "\n",
    "fullweights = 'seg_reg_real_full'\n",
    "print(f\"Saving model: {fullweights}\")\n",
    "learn.save(fullweights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "this will generate a bunch of images of segmentation masks and a list of filenames of top losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7fe9342206d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(fullweights)\n",
    "\n",
    "preds, targs, losses = learn.get_preds(with_loss=True) # validation set only\n",
    "print(preds.shape, targs.shape)\n",
    "len(preds)\n",
    "\n",
    "def save_tmask(tmask, fname='', norm=False): # save tensor mask\n",
    "    tmask_new = tmask[0].squeeze().cpu().numpy() \n",
    "    use_min, use_max = 0, np.max(np.array(colors))    # use scale of max ring count\n",
    "    if norm: use_min, use_max = tmask_new.min(), tmask_new.max()   # auto scale for just this image\n",
    "    rescaled = (255.0 / use_max * (tmask_new - use_min)).astype(np.uint8)\n",
    "    im = Image.fromarray(rescaled)\n",
    "    if fname != '': im.save(fname)\n",
    "    return im\n",
    "\n",
    "seg_img_dir = 'seg_reg_images'\n",
    "#!rm -rf {seg_img_dir};  # leave 'em\n",
    "! mkdir {seg_img_dir}\n",
    "\n",
    "results = []\n",
    "for i in range(len(preds)):\n",
    "    #line_list = [dls.valid.items[i].stem]+[round(targs[i].cpu().numpy().item(),2), round(preds[i][0].cpu().numpy().item(),2), losses[i].cpu().numpy(), i]\n",
    "    filestem = dls.valid.items[i].stem\n",
    "    line_list = [filestem]+[losses[i].cpu().numpy(), i]\n",
    "    save_tmask(preds[i], seg_img_dir+'/'+filestem+'_pred.png')\n",
    "    results.append(line_list)\n",
    "\n",
    "# store as pandas dataframe\n",
    "res_df = pd.DataFrame(results, columns=['filename', 'loss','i'])\n",
    "\n",
    "res_df = res_df.sort_values('loss', ascending=False) # top loss order\n",
    "res_df.to_csv(f'segreg_top_losses_real_k{k}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
