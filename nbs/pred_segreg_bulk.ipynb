{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq espiownage fastai wwf # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Segmentation Regression - In Bulk (new Images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Acknowledgement: I took [Zach Mueller's Image Segmentation tutoral notebook](https://walkwithfastai.com/Segmentation) (based on the main FastAI lesson notebook) and modified it to do regression (as per Zach's suggestions) and to work with my own data.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq espiownage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from espiownage.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's just get clear from the start which model we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_load = 'seg_reg_full_real_2' # .pth'\n",
    "\n",
    "imgdir = '/home/shawley/datasets/zooniverse_steelpan/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find the exact imports for everything we use today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.xtras import Path\n",
    "\n",
    "from fastai.callback.hook import summary\n",
    "from fastai.callback.progress import ProgressCallback\n",
    "from fastai.callback.schedule import lr_find, fit_flat_cos\n",
    "\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastai.data.transforms import get_image_files, FuncSplitter, Normalize\n",
    "\n",
    "from fastai.layers import Mish   # MishJIT gives me trouble :-( \n",
    "from fastai.losses import BaseLoss, MSELossFlat, CrossEntropyLossFlat, BCEWithLogitsLossFlat\n",
    "from fastai.optimizer import ranger\n",
    "\n",
    "from fastai.torch_core import tensor\n",
    "\n",
    "from fastai.vision.augment import aug_transforms\n",
    "from fastai.vision.core import PILImage, PILMask\n",
    "from fastai.vision.data import ImageBlock, MaskBlock, imagenet_stats\n",
    "from fastai.vision.learner import unet_learner\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import resnet34\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawley/envs/espi/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/home/shawley/envs/espi/lib/python3.8/site-packages/torch/_tensor.py:1023: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:760.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "path = Path('/home/shawley/datasets/espiownage-cleaner/')  # real data is local and private \n",
    "bin_size = 0.7  \n",
    "maskdir = path / ('masks_'+str(bin_size))\n",
    "path_im = path/'images'\n",
    "path_lbl = path/maskdir\n",
    "meta_names = sorted(glob.glob(str(path/'annotations')+'/*.csv'))\n",
    "fnames = [meta_to_img_path(x, img_bank=path_im) for x in meta_names]\n",
    "random.shuffle(fnames)\n",
    "lbl_names = get_image_files(path_lbl)\n",
    "get_msk = lambda o: path/maskdir/f'{o.stem}_P{o.suffix}'\n",
    "colors = list(range(int(11/bin_size) + 1))\n",
    "codes = [str(n) for n in range(len(colors))]; codes\n",
    "sz = (384,512)\n",
    "db = DataBlock(blocks=(ImageBlock, MaskBlock(codes)),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(),\n",
    "    get_y=get_msk,\n",
    "    batch_tfms=[*aug_transforms(size=sz, flip_vert=True), Normalize.from_stats(*imagenet_stats)])\n",
    "    \n",
    "dls = db.dataloaders(path/'images', fnames=fnames, bs=2)  # smaller batch size because we're now full size\n",
    "dls.vocab = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawley/envs/espi/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f6da18775b0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = ranger \n",
    "hrfac = 1.2  # 'headroom factor'\n",
    "codes = [str(n) for n in range(16)]; codes\n",
    "y_range=(0,int(len(codes)*hrfac))  # balance between \"clamping\" to range of real data vs too much \"compression\" from sigmoid nonlineari\n",
    "learn = unet_learner(dls, resnet34, n_out=1, y_range=y_range, loss_func=MSELossFlat(), self_attention=True, act_cls=Mish, opt_func=opt)\n",
    "learn.load('seg_reg_full_real_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tmask(tmask, fname='', norm=False): # save tensor mask\n",
    "    tmask_new = tmask[0].squeeze().cpu().numpy() \n",
    "    use_min, use_max = 0, np.max(np.array(colors))    # use scale of max ring count\n",
    "    if norm: use_min, use_max = tmask_new.min(), tmask_new.max()   # auto scale for just this image\n",
    "    rescaled = (255.0 / use_max * (tmask_new - use_min)).astype(np.uint8)\n",
    "    im = Image.fromarray(rescaled)\n",
    "    if fname != '': im.save(fname)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shawley/datasets/zooniverse_steelpan/06240907_proc_00000.png /home/shawley/datasets/zooniverse_steelpan/06240907_proc_01000.png\n",
      "14000\n"
     ]
    }
   ],
   "source": [
    "pfnames = sorted(glob.glob(imgdir+'/*.png'))\n",
    "print(pfnames[0],pfnames[1000])\n",
    "print(len(pfnames))\n",
    "\n",
    "pf = pfnames[0]\n",
    "im = img = PILImage.create(pf)\n",
    "\n",
    "#dlpred = dls.test_dl([pfile])\n",
    "#preds, _ = learn.get_preds(dl=dlpred)\n",
    "#preds = preds.squeeze(1)\n",
    "#print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dlpred = dls.test_dl(pfnames)\n",
    "preds, _ = learn.get_preds(dl=dlpred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘bulk_segreg’: File exists\n"
     ]
    }
   ],
   "source": [
    "outdir = 'bulk_segreg'\n",
    "!mkdir {outdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: saving bulk_segreg/06240907_proc_00000_RM.png\n",
      "250: saving bulk_segreg/06240907_proc_00250_RM.png\n",
      "500: saving bulk_segreg/06240907_proc_00500_RM.png\n",
      "750: saving bulk_segreg/06240907_proc_00750_RM.png\n",
      "1000: saving bulk_segreg/06240907_proc_01000_RM.png\n",
      "1250: saving bulk_segreg/06240907_proc_01250_RM.png\n",
      "1500: saving bulk_segreg/06240907_proc_01500_RM.png\n",
      "1750: saving bulk_segreg/06240907_proc_01750_RM.png\n",
      "2000: saving bulk_segreg/06240909_proc_00000_RM.png\n",
      "2250: saving bulk_segreg/06240909_proc_00250_RM.png\n",
      "2500: saving bulk_segreg/06240909_proc_00500_RM.png\n",
      "2750: saving bulk_segreg/06240909_proc_00750_RM.png\n",
      "3000: saving bulk_segreg/06240909_proc_01000_RM.png\n",
      "3250: saving bulk_segreg/06240909_proc_01250_RM.png\n",
      "3500: saving bulk_segreg/06240909_proc_01500_RM.png\n",
      "3750: saving bulk_segreg/06240909_proc_01750_RM.png\n",
      "4000: saving bulk_segreg/06240910_proc_00000_RM.png\n",
      "4250: saving bulk_segreg/06240910_proc_00250_RM.png\n",
      "4500: saving bulk_segreg/06240910_proc_00500_RM.png\n",
      "4750: saving bulk_segreg/06240910_proc_00750_RM.png\n",
      "5000: saving bulk_segreg/06240910_proc_01000_RM.png\n",
      "5250: saving bulk_segreg/06240910_proc_01250_RM.png\n",
      "5500: saving bulk_segreg/06240910_proc_01500_RM.png\n",
      "5750: saving bulk_segreg/06240910_proc_01750_RM.png\n",
      "6000: saving bulk_segreg/06240912_proc_00000_RM.png\n",
      "6250: saving bulk_segreg/06240912_proc_00250_RM.png\n",
      "6500: saving bulk_segreg/06240912_proc_00500_RM.png\n",
      "6750: saving bulk_segreg/06240912_proc_00750_RM.png\n",
      "7000: saving bulk_segreg/06240912_proc_01000_RM.png\n",
      "7250: saving bulk_segreg/06240912_proc_01250_RM.png\n",
      "7500: saving bulk_segreg/06240912_proc_01500_RM.png\n",
      "7750: saving bulk_segreg/06240912_proc_01750_RM.png\n",
      "8000: saving bulk_segreg/06240913_proc_00000_RM.png\n",
      "8250: saving bulk_segreg/06240913_proc_00250_RM.png\n",
      "8500: saving bulk_segreg/06240913_proc_00500_RM.png\n",
      "8750: saving bulk_segreg/06240913_proc_00750_RM.png\n",
      "9000: saving bulk_segreg/06240913_proc_01000_RM.png\n",
      "9250: saving bulk_segreg/06240913_proc_01250_RM.png\n",
      "9500: saving bulk_segreg/06240913_proc_01500_RM.png\n",
      "9750: saving bulk_segreg/06240913_proc_01750_RM.png\n",
      "10000: saving bulk_segreg/06240914_proc_00000_RM.png\n",
      "10250: saving bulk_segreg/06240914_proc_00250_RM.png\n",
      "10500: saving bulk_segreg/06240914_proc_00500_RM.png\n",
      "10750: saving bulk_segreg/06240914_proc_00750_RM.png\n",
      "11000: saving bulk_segreg/06240914_proc_01000_RM.png\n",
      "11250: saving bulk_segreg/06240914_proc_01250_RM.png\n",
      "11500: saving bulk_segreg/06240914_proc_01500_RM.png\n",
      "11750: saving bulk_segreg/06240914_proc_01750_RM.png\n",
      "12000: saving bulk_segreg/06241902_proc_00000_RM.png\n",
      "12250: saving bulk_segreg/06241902_proc_00250_RM.png\n",
      "12500: saving bulk_segreg/06241902_proc_00500_RM.png\n",
      "12750: saving bulk_segreg/06241902_proc_00750_RM.png\n",
      "13000: saving bulk_segreg/06241902_proc_01000_RM.png\n",
      "13250: saving bulk_segreg/06241902_proc_01250_RM.png\n",
      "13500: saving bulk_segreg/06241902_proc_01500_RM.png\n",
      "13750: saving bulk_segreg/06241902_proc_01750_RM.png\n"
     ]
    }
   ],
   "source": [
    "for i, pfile in enumerate(pfnames):\n",
    "    mfile = outdir+'/'+str(Path(pfile).stem)+'_RM.png'\n",
    "    if i% 250 == 0: print(f\"{i}: saving {mfile}\") \n",
    "    im = save_tmask(preds[i], mfile)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
